#Brains blood weight

I recently found a view of the world that felt more relaxing.
Saying science **explains** the universe always felt wrong, because when I thought that, I always had an example where I wanted to ask another why.
Take gravity for example. Saying we fall down because masses attract each other is OK... but why FFS?
And now you're telling me that big events in the universe bend gravity?
Instead, I now consider that science **predicts** or **describes** events in a broader and broader context, and suddenly, my brains feel lighter.

Mental models are how you think about the world. Some are very useful to me, like cynefin, [lean](https://planet-lean.com/), [Wardley maps](https://medium.com/wardleymaps), TDD, DDD, [John Cutler's product management view](https://medium.com/@johnpcutler)...
Some are too simplistic to be applicable in a realistic context, like the test pyramid, scrum, SAFe, or the SOLID principles.
Simplistic models are useful for talking and giving an entry point into a subject matter, but not as a guideline to take decisions in most concrete situations.

You may notice that the models that are useful to me are simple, for most of them.
They are not simplistic, though.
They reflect the complexity of the world. They are difficult to understand and apply.

I can feel it when a model is a better fit for a given situation.
When I'm using the right mental model, I feel more relaxed.
On the other hand, when I need to bend reality to fit a model, I feel more panic, more pressure in my head.
I call this brains blood weight.
The more blood I need in my head to make sense of something, the more tired I am.

Take scrum and lean, for example.
I spent years understanding eath of them.
Both are difficult. Both were useful to me, at least to help me adapt my view of the world.
However, scrum now feels like trying to horseshoe reality into an arbitrary framework.
Lean, on the other hand, feels like it better encompasses the uncertainty and diversity of situations, yet giving guidelines to better adapt to these situations.
I can feel my brains firing less "feels akward" alerts when using lean, thus decreasing the blood weight in my head.

#Unlearning

To maintain your brains blood weight at a bearable level, your mental models must evolve with your experience of your evolving environment.
You don't want to become your grumpy old uncle, always complaining about how the world was better back in the days.
Living in a world that doesn't fit your mental models makes you fill in the gap.
Filling in the gap is an exponential activity.
It increases your brains blood weight.
Brains blood weight makes you tired and grumpy.

Your mental models are your current grid for understanding the world.
They are often based on someone else's mental model, and you often refer to them using the same name, even though you might have a different understanding of the same concept.
For example, my understanding of cynefin is different than [Dave Snowden's](https://www.youtube.com/watch?v=N7oz366X0-8) or [Liz Keogh's](https://lizkeogh.com/cynefin-for-everyone/). Still, we're using the same word.
If you view your comprehension of a model as a simplistic one-dimensional value, you can consider that I understand a lot less of cynefin that Dave Snowden (you wouldn't take much risk).
You can thus consider I'm on my way to understanding cynefin.
During this process, I adapt my existing mental models to fit my new cynefin view of the world.
To some extent, I unlearn my existing mental models to adopt a new one in the family.

Unlearning happens all the time. There are a few fundamental limitations that make humanity what it is.
Our lifespan and the weak points of our body (and now our planet), and the amount of info one can process in their brains.
Because our brains are tiny, we reduce the world's complexity to a few simple rules. Otherwise we couldn't make sense of it.
This is what a mental model is, by the way. A simplification of the world. And this is why [all models are wrong, but some are useful(https://en.wikipedia.org/wiki/All_models_are_wrong).
Anyway, when we add new rules, we need to get rid, or factor in, older ones, because tiny brains.
This is unlearning. It is necessary, it is a continuous process, and it feels good by decreasing your brains blood weight.

As you can see in this article, I simplified the world of mental models in order to make sense of them.
Is this mental model of mental models simplistic? So far it doesn't feel so to me. It probably is simplistic to someone else.
It might become simplistic to me, when I encounter more concrete situations that don't fit this model, but that I need to make sense of anyway.
Does it help me adapt my mental models to real life? Definitely.
Does it help me in real life situations? I can feel it helping me learn new things, so yes.
Can I measure it? Definitely not. It's totally subjective, and evolves with time.
